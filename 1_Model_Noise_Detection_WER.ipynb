{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kntcRc6fH4SM"
      },
      "source": [
        "## Acessar o Dataset e Imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ukivWpe2Zfe"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV88dlCGWLlD"
      },
      "outputs": [],
      "source": [
        "!pip install librosa scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3SUfAiEWLlD"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer\n",
        "!pip install num2words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by-YSLn9WLlE"
      },
      "outputs": [],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYW7F-hmWLlE"
      },
      "outputs": [],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEUdftcWWLlE"
      },
      "outputs": [],
      "source": [
        "!pip install num2words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0reP_nxRh_o"
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWZjYdJkW9br"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WylFPgchkAAx"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import torch\n",
        "from torchaudio.transforms import Resample\n",
        "from IPython import display as disp\n",
        "from jiwer import wer\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnj7LfDG2rkD"
      },
      "outputs": [],
      "source": [
        "from num2words import num2words\n",
        "import re\n",
        "from decimal import Decimal, InvalidOperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJVa3mb5WPvN"
      },
      "source": [
        "###Dataset\n",
        "Vamos importar o nosso CSV, para usa-lo em análises futuras e também implementar a análise juntamente com os áudios separados em uma pasta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R05z8M51H9ph"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyK_5N9aWLlE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Aqui você pode substituir com o caminho para o seu arquivo CSV\n",
        "csv_file = \"/content/DataSets/dataset/metadata.csv\"\n",
        "\n",
        "\n",
        "# Carregar o dataset\n",
        "dataset = pd.read_csv(csv_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFp87A9C9GsA"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(dataset[\"audio_segmentado\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FzJeEsFjb13"
      },
      "outputs": [],
      "source": [
        "# Removemos colunas que não serão utilizadas\n",
        "colunas_para_remover = ['locutor', 'sentimento','sotaque'] # Exemplos de colunas\n",
        "dataset = dataset.drop(colunas_para_remover, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doNmSMfA-fjw"
      },
      "outputs": [],
      "source": [
        "contagem_valores = dataset['nivel_ruido'].value_counts()\n",
        "\n",
        "# Filtrando apenas os valores que se repetem (aparecem mais de uma vez)\n",
        "valores_repetidos = contagem_valores[contagem_valores > 1]\n",
        "\n",
        "# Imprimindo os valores que se repetem\n",
        "print(valores_repetidos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VhOAPCpk9w-"
      },
      "source": [
        "# RMS + WER + Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIp9ir5mPNv4"
      },
      "source": [
        "Calcular a Amplitude RMS: RMS (Root Mean Square) é um método comum para medir a amplitude do sinal de áudio, que pode ser usado para estimar o nível de ruído. A amplitude RMS é calculada como a raiz quadrada da média dos quadrados das amplitudes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F85ZAYMPY83"
      },
      "source": [
        "Converter para Decibéis: Para converter a amplitude RMS para decibéis, usamos a fórmula 20 * log10(amplitude).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfDoYuhZk1sh"
      },
      "source": [
        "## Transcrição humana e sua normalização\n",
        "Temos a transcrição humana já anotada no dataset, por isso precisamos do CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMYX5JkRkzwp"
      },
      "outputs": [],
      "source": [
        "def coleta_transcricao_humana(id_audio):\n",
        "    # Acessar a linha específica utilizando o ID do audio (assumindo que 'audio_segmentado' é a coluna com esses IDs)\n",
        "    linha = dataset[dataset['audio_segmentado'] == id_audio]\n",
        "\n",
        "    # Acessando a transcrição humana associada a esse segmento de áudio\n",
        "    transcricao_humana = linha['transcricao_normalizada'].values[0] if not linha.empty else \"Transcrição não encontrada.\"\n",
        "\n",
        "    # print(f\"Transcrição Humana Normalizada: {transcricao_humana}\")\n",
        "    return transcricao_humana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YRNrwcVlY_8"
      },
      "source": [
        "## Transcrição obtida normalização\n",
        "Vamos normalizar as transcrições obtidas pelo modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vg3WuHsOg7p"
      },
      "source": [
        "### Normalizar áudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGuimpSH-IlY"
      },
      "source": [
        "####Converter numero por extenso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJwn6O8ZNecT"
      },
      "outputs": [],
      "source": [
        "# Função para converter números em extenso\n",
        "def converter_em_extenso(input):\n",
        "    # Verifica se o input é um número válido\n",
        "    try:\n",
        "        # Tentativa de conversão para Decimal para garantir que o valor é numérico\n",
        "        num = Decimal(re.sub(r'[^\\d.]', '', input))\n",
        "        return num2words(num, lang='pt_BR')\n",
        "    except InvalidOperation:\n",
        "        # Se não for possível converter, retorna o input original ou uma mensagem de erro\n",
        "        return input  # ou \"valor inválido\"\n",
        "\n",
        "# Função atualizada para verificar e extrair números\n",
        "def verificar_numero(frase):\n",
        "    numeros = re.findall(r'\\d+', frase)\n",
        "    if numeros:\n",
        "        return numeros[0]  # Retorna o primeiro número encontrado\n",
        "    return None  # Retorna None se nenhum número for encontrado\n",
        "\n",
        "# Função para substituir números na frase por sua representação por extenso\n",
        "def substituir_numeros_por_extenso(frase):\n",
        "    numeros = re.findall(r'\\d+', frase)\n",
        "    for num in numeros:\n",
        "        frase = frase.replace(num, converter_em_extenso(num), 1)\n",
        "    return frase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UELofmRE-EQu"
      },
      "source": [
        "####Normalização do texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nlpnawnz5lm"
      },
      "outputs": [],
      "source": [
        "# Função de normalização atualizada para incluir a substituição de números\n",
        "def normalize_text(text):\n",
        "    text = text.lower()  # Converter para minúsculas\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remover pontuação\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remover espaços extras\n",
        "    if verificar_numero(text):  # Se houver números, substitua por extenso\n",
        "        text = substituir_numeros_por_extenso(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb9NHMry0TFY"
      },
      "source": [
        "##Modelo\n",
        "Vamos então usar um modelo que seja eficiente para transcrever os áudios. O modelo fica a seu critério, usamos aqui o Distill Whisper do Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUx4FnYh7Rbg"
      },
      "outputs": [],
      "source": [
        "# Aqui você pode adicionar o seu modelo de transcrição speech to text\n",
        "# Optamos pelo modelo Whisper, fica a sua escolha.\n",
        "lang = \"pt\"\n",
        "model_name = \"pierreguillou/whisper-medium-portuguese\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfIiGsdG0c3K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# carregamos e processamos o modelo\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NemWkqDYz88d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import librosa\n",
        "\n",
        "# Aqui fazemos um teste para saber se o modelo está rodando na GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# A função que realiza a inferência, normaliza a transcrição e substitui números por extenso\n",
        "def transcribe_distil_whisper(audio_path):\n",
        "    # Carregar o áudio\n",
        "    raw_audio, _ = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "    # Processar o áudio para criar os tensores de entrada e enviar para a GPU\n",
        "    inputs = processor(raw_audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
        "\n",
        "    # Colocar o modelo em modo de avaliação e enviá-lo para a GPU\n",
        "    model.eval().to(device)\n",
        "\n",
        "    # Realizar a inferência\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(inputs)\n",
        "\n",
        "    # Decodificar a transcrição e normalizá-la\n",
        "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    normalized_transcription = normalize_text(transcription)\n",
        "    return normalized_transcription\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdpkyRzMmeQ3"
      },
      "source": [
        "##Calculo do RMS\n",
        "Calculamos o RMS e também criamos listas para armazenar os valores gerados pela análise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF7A2hXB1HNY"
      },
      "outputs": [],
      "source": [
        "# Inicializando listas para coletar dados de nível de ruído e WER\n",
        "niveis_de_ruido = []\n",
        "classificacoes_de_ruido = []\n",
        "erros_distil_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvxCBxrmmltv"
      },
      "outputs": [],
      "source": [
        "# Criamos algumas funções para análisar o audio.\n",
        "# Primeiro calculamos o nível de ruido atráves do RMS\n",
        "def calcular_nivel_de_ruido(caminho_do_audio):\n",
        "    audio, sr = librosa.load(caminho_do_audio)\n",
        "    # Reproduzir o áudio\n",
        "    rms = np.sqrt(np.mean(audio**2))\n",
        "    nivel_de_ruido_db = 20 * np.log10(rms) if rms > 0 else -np.inf\n",
        "    return nivel_de_ruido_db\n",
        "\n",
        "# Depois criamos outra função para verificar o nível de wer e distribuir sua classificação com base nos valores\n",
        "def classificar_nivel_de_ruido(nivel_de_ruido, erro_distil):\n",
        "    if erro_distil <= 0.36:\n",
        "        print(\"Wer = \", erro_distil)\n",
        "        return \"Nenhum\"\n",
        "    elif erro_distil <= 0.45:\n",
        "        print(\"Wer = \", erro_distil)\n",
        "        return \"Pouco\"\n",
        "    elif erro_distil > 0.45 and erro_distil < 0.70:\n",
        "        print(\"Wer = \", erro_distil)\n",
        "        return \"Médio\"\n",
        "    else:\n",
        "        print(\"Wer = \", erro_distil)\n",
        "        return \"Muito\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gTObbiS_OhK"
      },
      "source": [
        "## Calculando o WER\n",
        "\n",
        "\"Word Error Rate\" (Taxa de Erro de Palavras), é uma métrica usada para avaliar a precisão de sistemas de reconhecimento de voz, como áudios no nosso caso. Ela calcula a proporção de palavras incorretamente reconhecidas em comparação com uma transcrição de referência (Transcrição Humana), considerando inserções, deleções e substituições de palavras. É expressa como uma porcentagem, onde valores menores indicam melhor desempenho.\n",
        "\n",
        "Usamos o WER para entender se o nosso modelo está se comportando bem na sua análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdVhoVqgSqO"
      },
      "outputs": [],
      "source": [
        "# Criamos uma função para calcular o WER\n",
        "# com base na transcrição humana e transcrição obtida pelo modelo\n",
        "def calcular_wer(transcricao_referencia, transcribe_obtida_distil_whisper):\n",
        "    print(f\"{transcricao_referencia}\\n----\\n{transcribe_obtida_distil_whisper}\\n----\\n\")\n",
        "    erro_distil = wer(transcricao_referencia, transcribe_obtida_distil_whisper)\n",
        "    return erro_distil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYfuE77V4ede"
      },
      "outputs": [],
      "source": [
        "def analisar_audio_e_transcricao(caminho_do_audio, transcricao_referencia, transcribe_obtida_distil_whisper):\n",
        "    # Funções calcular_nivel_de_ruido e classificar_nivel_de_ruido precisam estar definidas\n",
        "    nivel_de_ruido = calcular_nivel_de_ruido(caminho_do_audio)\n",
        "    niveis_de_ruido.append(nivel_de_ruido)\n",
        "    # Chama calcular_wer com todos os argumentos corretamente para cada par de transcrições\n",
        "    erro_palavras_distil = calcular_wer(transcricao_referencia, transcribe_obtida_distil_whisper)\n",
        "    classificacao_ruido = classificar_nivel_de_ruido(nivel_de_ruido, erro_palavras_distil)\n",
        "    classificacoes_de_ruido.append(classificacao_ruido)\n",
        "    erros_distil_list.append(erro_palavras_distil)\n",
        "\n",
        "    # Imprime resultados\n",
        "    print(f\"Nível de Ruído em dB: {nivel_de_ruido:.2f} dB\")\n",
        "    print(f\"Classificação do Nível de Ruído: {classificacao_ruido}\")\n",
        "\n",
        "    # Retorna um dicionário com os resultados\n",
        "    return {\n",
        "        'erro_palavras_distil': erro_palavras_distil,\n",
        "        'classificacao_ruido': classificacao_ruido,\n",
        "        'nivel_de_ruido': nivel_de_ruido\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf0SCilHlJ7A"
      },
      "source": [
        "# Classificação dos ruidos\n",
        "Aqui é onde chamamos todas as funções anteriores e fazemos a classificação, assim que cada áudio é processado, o algoritmo vai criar um dataset novo e depois vai atualizando com as novas informações atualizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4BD7XPWAXp3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from speech_recognition import UnknownValueError\n",
        "\n",
        "# Função para verificar se um arquivo existe no caminho especificado\n",
        "def verificar_existencia_arquivo(caminho):\n",
        "    return os.path.exists(caminho)\n",
        "\n",
        "# Inicializa a contagem de áudios processados\n",
        "contagem_processados = 0\n",
        "\n",
        "# Adiciona novas colunas ao DataFrame\n",
        "dataset['taxa_de_wer'] = None\n",
        "dataset['nivel_ruido_distill'] = None\n",
        "dataset['niveis_de_ruido_dB'] = None\n",
        "\n",
        "# Itera sobre as primeiras 10 linhas do DataFrame\n",
        "for index, row in dataset.iloc[0:10].iterrows():\n",
        "    # Obtém o ID do áudio segmentado da linha atual\n",
        "    id_audio = row['audio_segmentado']\n",
        "    # Constroi o caminho completo do arquivo de áudio\n",
        "    caminho_do_audio = f'/content/DataSets/dataset/audios/{id_audio}'\n",
        "    print(caminho_do_audio)\n",
        "\n",
        "    # Verifica se o arquivo de áudio existe\n",
        "    if verificar_existencia_arquivo(caminho_do_audio):\n",
        "        # Coleta a transcrição humana de referência\n",
        "        transcricao_referencia = coleta_transcricao_humana(id_audio).lower()\n",
        "\n",
        "        try:\n",
        "            # Obtém a transcrição usando a função transcribe_distil_whisper\n",
        "            transcribe_obtida_distil_whisper = transcribe_distil_whisper(caminho_do_audio).lower()\n",
        "            # Analisa o áudio e a transcrição obtida\n",
        "            resultado_analise = analisar_audio_e_transcricao(caminho_do_audio, transcricao_referencia, transcribe_obtida_distil_whisper)\n",
        "            # Atualiza o DataFrame com os resultados da análise\n",
        "            dataset.at[index, 'taxa_de_wer'] = resultado_analise['erro_palavras_distil']\n",
        "            dataset.at[index, 'nivel_ruido_distill'] = resultado_analise['classificacao_ruido']\n",
        "            dataset.at[index, 'niveis_de_ruido_dB'] = resultado_analise['nivel_de_ruido']\n",
        "            # Incrementa a contagem de áudios processados\n",
        "            contagem_processados += 1\n",
        "\n",
        "        except UnknownValueError:\n",
        "            # Tratamento de erro para quando a transcrição não é possível\n",
        "            print(f\"Não foi possível transcrever o áudio: {id_audio}\")\n",
        "            dataset.at[index, 'taxa_de_wer'] = 'Erro de transcrição'\n",
        "            dataset.at[index, 'nivel_ruido_distill'] = 'Erro de transcrição'\n",
        "            dataset.at[index, 'niveis_de_ruido_dB'] = 'Erro de transcrição'\n",
        "\n",
        "    else:\n",
        "        # Tratamento para quando o arquivo de áudio não é encontrado\n",
        "        print(f\"Arquivo não encontrado: {id_audio}\")\n",
        "        dataset.at[index, 'taxa_de_wer'] = 'Arquivo não encontrado'\n",
        "        dataset.at[index, 'nivel_ruido_distill'] = 'Arquivo não encontrado'\n",
        "        dataset.at[index, 'niveis_de_ruido_dB'] = 'Arquivo não encontrado'\n",
        "\n",
        "    # Exibe a contagem de áudios processados até o momento\n",
        "    print(f\"Áudios processados: {contagem_processados}/{len(dataset) - 1}\")\n",
        "    # Salva o DataFrame atualizado em um arquivo CSV a cada iteração para evitar perda de dados\n",
        "    dataset.to_csv('dataset_atualizado.csv', index=False)\n",
        "\n",
        "# Indica o término da análise de WER\n",
        "print(\"Finalizado toda análise de WER.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "6ukivWpe2Zfe",
        "eJVa3mb5WPvN",
        "yfDoYuhZk1sh",
        "7YRNrwcVlY_8",
        "rb9NHMry0TFY",
        "RdpkyRzMmeQ3",
        "5gTObbiS_OhK",
        "nf0SCilHlJ7A"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}